{
  
    
        "post0": {
            "title": "How to generate text?",
            "content": "Introduction . 본 포스팅에서는 텍스트를 생성하는 방법에 대하여 알아보겠습니다. . 해당 포스팅은 patrick von platen님의 포스팅을 번역한 내용과 제가 직접 🤗 transformers를 뜯어본 내용을 기반으로 작성하였습니다. . https://huggingface.co/blog/how-to-generate | . Using different decoding methods for language generation with Transformers . Introduction . 최근 몇 년 동안 OpenAI의 GPT-2 모델과 같이 수백만 개의 웹 페이지에서 훈련된 large-scale transformer 기반 언어 모델의 등장으로 open-ended language generation에 대한 관심이 높아졌습니다. Conditioned open-ended language generation의 결과는 굉장히 인상적입니다. . GPT2 on unicorns | XLNet | Controlled language with CTRL | . 2017년에 transformer가 등장한 이래로 아키텍쳐를 수정하는 방법 및 방대한 unsupervised 학습 데이터(self-supervised를 위한)들이 있지만 더 나은 디코딩 방법(better decoding methods) 또한 중요한 역할을 했습니다. . 이 블로그 포스트는 다양한 디코딩 전략에 대한 간략한 개요를 제공하고 더 중요한 것은 유명한 🤗 transformers 라이브러리를 사용하여 아주 적은 노력으로 이를 구현할 수 있는 방법을 보여줍니다! . jinmang2: 또한 제 블로그 포스팅에서 여러분들은 🤗 transformers에서 Decoding methods가 어떻게 구현되어 있는지도 알 수 있습니다. | . 본 게시글에서 다루는 모든 기능들(functionalities)은 모두 auto-regressive language generation(더 자세한 내용은 Jay Alammar님의 포스팅을 확인해주세요)에 사용할 수 있습니다. auto-regressive란 간단히 말해 아래 가정을 기반으로 둔 방법론입니다. . Assumption ========== The probability distribution of a word sequence can be decomposed into the product of conditional next word distributions. . word sequence, 즉, 단어로 이루어진 수열(문장이라고 이해하시면 됩니다)은 다음 단어가 나올 조건부 분포들의 곱으로 분해가 가능하다라는 전제를 깔고 있습니다. . 수식으로 보겠습니다. . $$P(w_{1:T}|W_0)= prod_{t=1}^{T}P(w_t|w_{1:t-1},W_0), ; text{with} , w_{1:0}= emptyset$$ . $W_0$은 initial context word sequence | $T$는 문장의 길이입니다. patrick님 포스팅 본문에서는 생성된 문장의 길이를 의미하시는 것 같습니다. 생성은 단어(혹은 토큰) 단위로 길이가 1씩 늘어나기 때문에 on-the-fly라는 표현을 사용하신 것 같습니다. | . | Timestep $t$가 $T$가 되면? 문장을 전부 분해했다는 뜻이겠죠?(conditional next word dists.로) 이 때는 $P(w_t|w_{1:t-1},W_0)$에서 EOS 토큰이 생성됩니다. EOS는 End of Sentence(혹은 Sequence)의 약자로 문장의 끝을 의미합니다. | . | . 이제 가장 중요한 네 가지 decoding 방법에 대하여 소개해드리도록 하겠습니다. . 블로그 포스팅의 예시를 보셔도 좋고 아무래도 한국어로 번역된 포스팅이기 때문에 한국어 언어 모델로 예시를 들어드리는 것이 보기 좋을 것 같습니다. 이에 대한 세팅을 수행하죠. . tensorflow는 사용하지 않습니다. | . !pip install -q git+https://github.com/huggingface/transformers.git . KoGPT2 . 예시에서 사용할 모델은 SKT에서 개발한 KoGPT2이며 자세한 설명은 아래 링크를 참고해주세요. . https://github.com/SKT-AI/KoGPT2 | https://huggingface.co/skt/kogpt2-base-v2 | . 간략한 소개는 다음과 같습니다. . Vocab size: 51,200 | 이모지, 이모티콘 등을 추가하여 해당 토큰의 인식 능력 개선 | unused token을 100개 사용하여 필요한 task에 따라 자유롭게 정의 가능 | metaspace는 ▁ | . Model # of params Type # of layers # of heads ffn_dim hidden_dims . kogpt2-base-v2 | 125M | Decoder | 12 | 12 | 3072 | 768 | . 사용한 데이터는 한국어 위키 백과, 뉴스, 모두의 말뭉치 v1.0, 청와대 국민청원 등 다양한 데이터 | . from transformers import AutoTokenizer, AutoModelForCausalLM model_path_or_name = &quot;skt/kogpt2-base-v2&quot; tokenizer = AutoTokenizer.from_pretrained(model_path_or_name, force_download=True) model = AutoModelForCausalLM.from_pretrained(model_path_or_name, force_download=True) . Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained. . tokenizer # Rust로 구현된 `Fast`한 tokenizer . PreTrainedTokenizerFast(name_or_path=&#39;skt/kogpt2-base-v2&#39;, vocab_size=51200, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side=&#39;right&#39;, special_tokens={&#39;bos_token&#39;: &#39;&lt;|endoftext|&gt;&#39;, &#39;eos_token&#39;: &#39;&lt;|endoftext|&gt;&#39;, &#39;unk_token&#39;: &#39;&lt;|endoftext|&gt;&#39;}) . tokenizer.tokenize(&quot;근육이 커지기 위해서는&quot;) . [&#39;▁근육이&#39;, &#39;▁커&#39;, &#39;지기&#39;, &#39;▁위해서는&#39;] . model.__class__.__name__ # AutoModelForCausalLM으로 GPT2의 CLM class 호출 . &#39;GPT2LMHeadModel&#39; . num_of_parameters = sum(p.numel() for n, p in model.named_parameters()) print(f&quot;{num_of_parameters}&quot;) # 125M . 125164032 . Calculate word probability . Q) 단어별 확률은 어떻게 구하나요? . A) 위에서 GPT2ForLMHeadModel을 Causal-LM을 수행하기 위한 모델로 불렀죠? 해당 모델이 left-to-right으로 contidional next word distribution을 모델링해줍니다! . LMHeadModel(Causal-LM을 하기 위한 모델)은 크게 세 파트로 나뉘어져 있습니다. . (1) word token/position embedding . 인코딩된 word sequence에 대해 embedding value를 계산합니다. | 단어(혹은 토큰)의 뜻을 word token embedding으로, | 단어(혹은 토큰)의 위치를 word position embedding으로 벡터화해줍니다. position embedding의 경우 layer에 해당 정보를 넣어주는 경우도 있지만 (relative position embedding) 해당 포스팅의 범주를 넘어서기 때문에 향후 소개하도록 하겠습니다. | . | . Note that: 아래 코드는 GPT2 script에서 발췌한 코드입니다! wte, wpe를 구하는 것은 model by model이에요!&quot; . word_sequence = &quot;근육이 커지기 위해서는&quot; inputs = tokenizer(word_sequence, return_tensors=&quot;pt&quot;) input_ids = inputs[&quot;input_ids&quot;] input_shape = input_ids.size() input_ids = input_ids.view(-1, input_shape[-1]) input_ids . tensor([[33245, 10114, 12748, 11357]]) . 실제로 모델 인풋에 어떻게 들어가나 확인해보죠. . import inspect # input_ids, attention_mask, token_type_ids, position_ids가 중요해요 # forward와 __call__의 관계는 `torch.nn.Module`을 상속받아서 그래요 # 이건 다음 학습 기회로! inspect.signature(model.transformer.forward).parameters . mappingproxy({&#39;input_ids&#39;: &lt;Parameter &#34;input_ids=None&#34;&gt;, &#39;past_key_values&#39;: &lt;Parameter &#34;past_key_values=None&#34;&gt;, &#39;attention_mask&#39;: &lt;Parameter &#34;attention_mask=None&#34;&gt;, &#39;token_type_ids&#39;: &lt;Parameter &#34;token_type_ids=None&#34;&gt;, &#39;position_ids&#39;: &lt;Parameter &#34;position_ids=None&#34;&gt;, &#39;head_mask&#39;: &lt;Parameter &#34;head_mask=None&#34;&gt;, &#39;inputs_embeds&#39;: &lt;Parameter &#34;inputs_embeds=None&#34;&gt;, &#39;encoder_hidden_states&#39;: &lt;Parameter &#34;encoder_hidden_states=None&#34;&gt;, &#39;encoder_attention_mask&#39;: &lt;Parameter &#34;encoder_attention_mask=None&#34;&gt;, &#39;use_cache&#39;: &lt;Parameter &#34;use_cache=None&#34;&gt;, &#39;output_attentions&#39;: &lt;Parameter &#34;output_attentions=None&#34;&gt;, &#39;output_hidden_states&#39;: &lt;Parameter &#34;output_hidden_states=None&#34;&gt;, &#39;return_dict&#39;: &lt;Parameter &#34;return_dict=None&#34;&gt;}) . 위에서 확인한 것 처럼 position type ids를 직접 입력에 넣어줄 수도 있지만 이번엔 직접 만들어줄게요! (실제로 source code에서 position_ids가 None이면 아래처럼 만들어줘요) . import torch position_ids = torch.arange(0, input_shape[-1], dtype=torch.long) position_ids = position_ids.unsqueeze(0).view(-1, input_shape[-1]) position_ids # 네 개의 토큰에 대한 위치 정보 . tensor([[0, 1, 2, 3]]) . Word token embedding의 경우 vocab의 수만큼 vector가 정의되어 있어야 합니다. . 하지만 Word position embedding의 경우 tokenizing의 결과로 나온 토큰의 수로 매핑이 되기 때문에 미리 max_length를 정해둬요. KoGPT2의 경우엔 1,024네요! . 위와 같은 이유로 wte와 wpe의 matrix shape은 다릅니다! . GPT2는 absolute position embedding을 사용하기 때문이에요! | Transformer의 SInusoidal encoding을 사용하면 extrapolate를 할 수 있기 때문에 저런 위치 고정 문제는 생기지 않겠죠! | . ( model.transformer.wte, # vocab_size X hidden_dim model.transformer.wpe, # max_position_length X hidden_dim ) . (Embedding(51200, 768), Embedding(1024, 768)) . inputs_embeds = model.transformer.wte(input_ids) position_embeds = model.transformer.wpe(position_ids) hidden_states = inputs_embeds + position_embeds hidden_states.shape # (batch_size, sequence length, hidden_dim) . torch.Size([1, 4, 768]) . (2) Transformer Layers . Self-Attention | Feed-Forward Network | 기타 모듈 등 | . print(f&quot;n_layers: {len(model.transformer.h)}&quot;) for i, block in enumerate(model.transformer.h): outputs = block(hidden_states) hidden_states = outputs[0] hidden_states = model.transformer.ln_f(hidden_states) # final layer norm . n_layers: 12 . hidden_states.shape . torch.Size([1, 4, 768]) . (3) Language Model Head . Transformer layer들을 통과하여 나온 hidden_states를 각 토큰 별 확률로 매핑 | . lm_logits = model.lm_head(hidden_states) lm_logits.shape # (batch_size, sequence_length, vocab_size) . torch.Size([1, 4, 51200]) . 이렇게 세 가지 과정을 거쳐서 모델은 Causal-LM, 이전 단어들로부터 다음 단어를 예측하는 Conditional next word distribution을 학습하게 됩니다. 추론에서는 이제부터 소개할 decoding 방법론으로 계산된 확률을 어떻게 사용하느냐 이것이 갈리겠지요! . Maximization . Greedy Search . Greedy search는 단순하게 다음 단어로 가장 높은 확률을 가지는 단어를 선택합니다. 수식으로 이를 다시 쓰면, . $$w_t= underset{w}{ mathrm{argmax}}{P(w|w_{1:t-1})}$$ . $W_0$는 생략된 것 같습니다. | . 이를 이미지로 그려보면 아래와 같습니다. . . The 라는 단어로부터 시작하여 알고리즘은 탐욕적으로(greedily) 다음으로 올 단어로 가장 높은 확률을 가지는 nice를 선택합니다. 이렇게 종료 시점까지 탐욕적으로 선택하면 위의 예시에서 최종적으로 생성된 word sequence는 (The, nice, woman)이 될 것입니다. . 해당 word sequence가 나올 확률은 $0.5 times 0.4 = 0.2$로 꽤나 높습니다. | . 구현 상세는 제가 뜯어보며 알아낸 정보를 다루는 Chapter 2에서 다루고 huggingface에서 어떻게 사용할 수 있는지 알아봅시다. . input_ids = tokenizer.encode(&quot;근육이 커지기 위해서는&quot;, return_tensors=&quot;pt&quot;) # CLM으로 문장을 생성 (output length가 128에 도달할 때 까지) greedy_output = model.generate(input_ids, max_length=128) print(&quot;Output: n&quot; + 100 * &#39;-&#39;) print(tokenizer.decode(greedy_output[0], skip_special_tokens=True)) . Output: - 근육이 커지기 위해서는 무엇보다 규칙적인 생활습관이 중요하다. 특히, 아침식사는 단백질과 비타민, 무기질 등 영양소가 풍부한 음식을 골고루 섭취하는 것이 좋다. 또한 규칙적인 운동은 근육을 강화시켜주는 효과가 있다. 특히, 아침식사는 단백질과 비타민, 무기질 등 영양소가 풍부한 음식을 골고루 섭취하는 것이 좋다. 또한 규칙적인 운동은 근육을 강화시켜주는 효과가 있다. 특히, 아침식사는 단백질과 비타민, 무기질 등 영양소가 풍부한 음식을 골고루 섭취하는 것이 좋다. 또한 규칙적인 운동은 근육을 강화시켜주는 효과가 있다. 근육을 강화시켜주는 운동은 근육을 강화시켜주는 효과가 있다. 근육을 강화시켜주는 운동은 근육을 강화 . 오... 잘 생성해냈군요 ㅎㅎ. 하지만 자세히 보면 규칙적인 생활습관이 중요하다고 내용을 반복하는 문제가 보이는군요...! . 이는 일반적으로 natural language generation에서 일반적인 문제이며 greedy search, beam search와 같은 maximization 기법에서 훨씬 더 심하게 발생됩니다. . Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models, Vijayakumar et al., 2016 | Generating High-Quality and Informative Conversation Responses with Sequence-to-Sequence Models, Shao et al., 2017 | . Greedy search의 주된 단점은 낮은 확률 사이에 숨겨진 높은 확률의 단어를 놓치는 것 입니다. 위의 예시에서도 (The, dog, has)를 놓쳤죠. 이 문장은 사실 $0.4 times 0.9 = 0.36$으로 위의 문장보다 조금 더 가능성이 있는 문장입니다. . 고맙게도 beam search가 위 문제를 조금 덜어줍니다! . alleviate입니다. 해결해주지는 않습니다... | . Beam Search . Beam search는 각 time step에서 가장 가능성이 높은 가설을 num_beams만큼 유지하고 결국 전체 확률이 가장 높은 가설(hypothesis)를 선택하여 숨겨진 높은 확률의 word sequence를 놓칠 위험을 줄입니다. . 아래 예시는 num_beams가 2일 때 beam search의 동작 과정입니다. . . Time step 1에서 가장 가능성이 높은 가설은 (The, nice)로 확률이 0.5, 그 다음으로 높은 확률을 보이는 가설은 (The, dog)로 확률이 0.4입니다. greedy search에서는 top-1만 선택했기 때문에 아래 가설이 무시되었지만 beam search에서는 num_beams만큼 가설을 유지하기 때문에 두 번째로 높은 확률을 가지는 가설 (The, dog)를 기각하지 않고 유지합니다. (어떻게 유지하는지는 Ch2) . Time step 2에서 (The, dog, has)는 0.36의 확률을 가지는 가설이고 greedy search의 결과였던 (The, nice, woman)은 0.2의 확률을 가지는 가설입니다. 어때요 확률이 뒤집혔죠? . Beam search는 항상 greedy search보다 높은 확률로 output sequence를 찾아줍니다. 하지만 가장 가능성이 있는 출력을 찾는 것은 보장되지 않죠. (sub-optimal solution) . transformers에서의 예시를 봅시다! . beam_output = model.generate( input_ids, max_length=128, num_beams=5, early_stopping=True ) print(&quot;Output: n&quot; + 100 * &#39;-&#39;) print(tokenizer.decode(beam_output[0], skip_special_tokens=True)) . Output: - 근육이 커지기 위해서는 피부 속 콜라겐과 엘라스틴의 생성을 촉진시키는 것이 중요하다. 콜라겐과 엘라스틴의 생성을 촉진시키기 위해서는 피부 속 콜라겐과 엘라스틴의 생성을 촉진시키는 것이 중요하다. 피부 속 콜라겐과 엘라스틴의 생성을 촉진시키기 위해서는 피부 속 콜라겐과 엘라스틴의 생성을 촉진시키는 것이 중요하다. 피부 속 콜라겐과 엘라스틴의 생성을 촉진시키기 위해서는 피부 속 콜라겐과 엘라스틴의 생성을 촉진시키는 것이 중요하다. 피부 속 콜라겐과 엘라스틴의 생성을 촉진시키기 위해서는 피부 속 콜라겐과 엘라스틴의 생 . 음... 하지만 출력에 여전히 동일한 word sequence의 반복이 포함되는 군요... . 이에 대한 간단한 해결책은 Paulus 연구진이 도입한 n-grams penalty(a.k.a word sequences of n words)를 사용하는 것입니다. . A Deep Reinforced Model for Abstractive Summarization, Paulus et al. (2017) | OpenNMT: Open-Source Toolkit for Neural Machine Translation, Klein et al. (2017) | . 가장 흔한 n-grams penalty는 이미 본 n-gram을 생성할 수 있는 다음 단어의 확률을 수동으로 0으로 설정하여 n-gram이 두 번 다시 나타나지 않도록 하는 것입니다. . no_repeat_ngram_size를 2로 설정하여 동일한 n-gram이 2번 이상 반복되지 않도록 수정해보죠! . beam_output = model.generate( input_ids, max_length=128, num_beams=5, no_repeat_ngram_size=2, early_stopping=True ) print(&quot;Output: n&quot; + 100 * &#39;-&#39;) print(tokenizer.decode(beam_output[0], skip_special_tokens=True)) . Output: - 근육이 커지기 위해서는 피부 속 콜라겐과 엘라스틴의 생성을 촉진시키는 것이 가장 중요하다. 콜라겐은 피부의 탄력을 유지하는 데 중요한 역할을 하기 때문에 피부 노화를 예방하고 탄력 있는 피부로 가꿔주는 것이 중요하다. 또한 피부 탄력이 떨어지기 쉬운 겨울철에는 보습과 영양을 동시에 챙길 수 있는 제품을 선택하는 것이 좋다. 겨울철에는 피부가 건조해지기 쉬우므로 충분한 수분을 섭취하는 것이 중요하다. 현대자동차(회장 정몽구)는 지난달 국내 자동차 판매량이 전년 동월 대비 4.2% 감소한 1만2천511대를 기록했다고 1일 밝혔다. 현대차는 지난해 12월 국내 시장에서 . 반복의 문제는 해결되었군요! (다만 갑분 현대자동차... 저는 다만 근육이 커지는 방법을 알고 싶었습니다만...) . 다만 patricks에 따르면 n-gram penalty는 주의해서 사용해야 합니다. 예를 들어 New York 시에 대해 생성된 기사는 2-gram penalty를 사용하면 전체 텍스트에서 도시 이름이 한 번만 나타나기 때문입니다. . Beam search의 또 다른 중요한 기능은 생성 후 top beams를 비교하고 목적에 가장 잘 맞는 generated beam을 선택할 수 있다는 점입니다. . 🤗 transformers에서 num_return_sequences 매개변수를 세팅하면 위의 작업을 수행할 수 있습니다. . num_return_sequences는 항상 num_beams보다 작아야 합니다. | . beam_outputs = model.generate( input_ids, max_length=128, num_beams=5, no_repeat_ngram_size=2, num_return_sequences=5, early_stopping=True ) # now we have 3 output sequences print(&quot;Output: n&quot; + 100 * &#39;-&#39;) for i, beam_output in enumerate(beam_outputs): decoded_text = tokenizer.decode(beam_output, skip_special_tokens=True) print(f&quot;{i}: {decoded_text}&quot;, end=&quot; n n&quot;) . Output: - 0: 근육이 커지기 위해서는 피부 속 콜라겐과 엘라스틴의 생성을 촉진시키는 것이 가장 중요하다. 콜라겐은 피부의 탄력을 유지하는 데 중요한 역할을 하기 때문에 피부 노화를 예방하고 탄력 있는 피부로 가꿔주는 것이 중요하다. 또한 피부 탄력이 떨어지기 쉬운 겨울철에는 보습과 영양을 동시에 챙길 수 있는 제품을 선택하는 것이 좋다. 겨울철에는 피부가 건조해지기 쉬우므로 충분한 수분을 섭취하는 것이 중요하다. 현대자동차(회장 정몽구)는 지난달 국내 자동차 판매량이 전년 동월 대비 4.2% 감소한 1만2천511대를 기록했다고 1일 밝혔다. 현대차는 지난해 12월 국내 시장에서 1: 근육이 커지기 위해서는 피부 속 콜라겐과 엘라스틴의 생성을 촉진시키는 것이 가장 중요하다. 콜라겐은 피부의 탄력을 유지하는 데 중요한 역할을 하기 때문에 피부 노화를 예방하고 탄력 있는 피부로 가꿔주는 것이 중요하다. 또한 피부 탄력이 떨어지기 쉬운 겨울철에는 보습과 영양을 동시에 챙길 수 있는 제품을 선택하는 것이 좋다. 겨울철에는 피부가 건조해지기 쉬우므로 충분한 수분을 섭취하는 것이 중요하다. 현대자동차(회장 정몽구)는 지난달 국내 자동차 판매량이 전년 동월 대비 4.2% 감소한 1만2천567대를 기록했다고 1일 밝혔다. 현대차는 지난해 12월 국내 시장에서 2: 근육이 커지기 위해서는 피부 속 콜라겐과 엘라스틴의 생성을 촉진시키는 것이 가장 중요하다. 콜라겐은 피부의 탄력을 유지하는 데 중요한 역할을 하기 때문에 피부 노화를 예방하고 탄력 있는 피부로 가꿔주는 것이 중요하다. 또한 피부 탄력이 떨어지기 쉬운 겨울철에는 보습과 영양을 동시에 챙길 수 있는 제품을 선택하는 것이 좋다. 겨울철에는 피부가 건조해지기 쉬우므로 충분한 수분을 섭취하는 것이 중요하다. 현대자동차(회장 정몽구)는 지난달 국내 자동차 판매량이 전년 동월 대비 4.2% 감소한 1만2천567대를 기록했다고 1일 밝혔다. 현대차는 지난해 12월 내수 판매 3: 근육이 커지기 위해서는 피부 속 콜라겐과 엘라스틴의 생성을 촉진시키는 것이 가장 중요하다. 콜라겐은 피부의 탄력을 유지하는 데 중요한 역할을 하기 때문에 피부 노화를 예방하고 탄력 있는 피부로 가꿔주는 것이 중요하다. 또한 피부 탄력이 떨어지기 쉬운 겨울철에는 보습과 영양을 동시에 챙길 수 있는 제품을 선택하는 것이 좋다. 겨울철에는 피부가 건조해지기 쉬우므로 충분한 수분을 섭취하는 것이 중요하다. 현대자동차(회장 정몽구)는 지난달 국내 자동차 판매량이 전년 동월 대비 4.2% 감소한 1만2천511대를 기록했다고 1일 밝혔다. 현대차는 지난해 12월 국내 판매 4: 근육이 커지기 위해서는 피부 속 콜라겐과 엘라스틴의 생성을 촉진시키는 것이 가장 중요하다. 콜라겐은 피부의 탄력을 유지하는 데 중요한 역할을 하기 때문에 피부 노화를 예방하고 탄력 있는 피부로 가꿔주는 것이 중요하다. 또한 피부 탄력이 떨어지기 쉬운 겨울철에는 보습과 영양을 동시에 챙길 수 있는 제품을 선택하는 것이 좋다. 겨울철에는 피부가 건조해지기 쉬우므로 충분한 수분을 섭취하는 것이 중요하다. 현대자동차(회장 정몽구)는 지난달 국내 자동차 판매량이 전년 동월 대비 4.2% 감소한 1만2천511대를 기록했다고 1일 밝혔다. 현대차는 지난해 12월 내수 판매 . 음... 반환받았지만 각 beam들이 크게 다르지 않습니다. . Open-ended generation에서 최근에 beam search가 최선이 아닐 수 있다는 몇 가지 이유가 제기되었습니다. . Beam search는 기계 번역이나 요약같이 원하는 생성의 길이가 어느 정도 예측 가능한 작업에서 매우 잘 동작합니다. 그러나 원하는 출력의 길이가 크게 달라질 수 있는 open-ended generation의 경우(대화 혹은 story 생성) 그렇지 않습니다. Correcting Length Bias in Neural Machine Translation , Murray et al., (2018) | Breaking the Beam Search Curse: A Study of (Re-)Scoring Methods and Stopping Criteria for Neural Machine Translation, Yang et al. (2018) | . | 위에서 확인했듯 beam search는 repetitive generation에 취약합니다. 이는 n-gram 혹은 다른 penalty로 적절히 조정하기가 어렵습니다. | Holtzman에 따르면, High quality human language는 다음 단어가 가장 높게 올 확률 분포를 따르지 않습니다. 즉 인간은 생성된 텍스트가 우리를 놀라게 하고(surprise) 지루하거나(boring) 예측할 수 없기를(not to be predictable) 원합니다. 저자는 BeamSearch로 생성된 text가 덜 놀랍다는 것을 아래 plot으로 보여줍니다. The Curious Case of Neural Text Degeneration, Ari Holtzman et al. (2019) | . | . . 자, 지루한 text는 그만 생성하고 randomness를 도입합시다 :) . Sampling . Temperature-Sampling . 가장 기본적인 형태의 sampling은 다음 단어 $w_t$를 conditional probability distribution에 따라 임의로 선택하는 것입니다. . $$w_t sim P(w|w_{1:t-1})$$ . 아래 시각화로 sampling 시 언어 생성에 대해 알아봅시다. . . 샘플링을 사용한 언어 생성은 더 이상 결정적이지 않습니다. . Maximization 기법(greedy, beam)은 가장 높은 확률을 가지는 가설만을 택했습니다. | . 단어 car은 beam을 3만큼 늘리지 않으면 이전 maximization 기법에서는 어떠한 경우에도 절대로 채택되지 않습니다. 하지만 정말 낮은 확률로 조건부 확률 분포 $P(w|`the`)$에서 단어 car가 추출될 수 있으며 다음 단어인 drives, is, turns가 조건부 확률 분포 $P(w|`the`,`car)$에서 추출될 것 입니다. . 🤗 transformers에서 do_sample 옵션을 활성화시키고 top-k sampling을 비활성화시켜서 위를 구현할 수 있습니다. . import random import torch import numpy as np def set_seed(seed: int = 42): &quot;&quot;&quot;Seed fixer (random, numpy, torch) Args: seed (:obj:`int`): The seed to set. &quot;&quot;&quot; random.seed(seed) np.random.seed(seed) torch.manual_seed(seed) torch.cuda.manual_seed(seed) torch.cuda.manual_seed_all(seed) # if use multi-GPU torch.backends.cudnn.deterministic = True torch.backends.cudnn.benchmark = False set_seed() . sample_output = model.generate( input_ids, do_sample=True, max_length=128, top_k=0, ) print(&quot;Output: n&quot; + 100 * &#39;-&#39;) print(tokenizer.decode(sample_output[0], skip_special_tokens=True)) . Output: - 근육이 커지기 위해서는 일단 교정에 힘써야 한다. 여기서 중요한 것은 교정을 잘못하였을 때 그 교정이 잘못 되었는지 한번 말해주면 스스로가 교정되는 것이다. 교정수술의 가장 큰 원칙은 교정이 어렵다고 하여 하는 것이다. 심한 경우에는 교정에만 전념하는 것이 최선의 방법이다. 특히 교정에 시간을 투자하다 보면 교정수술에 욕심이 생기게 되는 즉이 있다. 물론 이 방법은 교정이 기계적임을 이용하여 지속적인 교정수술을 하는 방법이지만, 교정을 잘 하면 오히려 기존의 교정수술에 비해 교정력이 더 강해질 수 있다. 또한 최선의 교정치료를 하면 개선된다. 즉 교정은 교정이 진행될수록 결국은 개선된다. 교 . 어... 내용은 차치하고 반복 문제는 안보이네요! 하지만 표현이 이상합니다. . 교정이 어렵다고 하여 하는 것이다. | 특히 교정에 시간을 투자하다 | 보면 교정수술에 욕심이 생시게 되는 즉이 있다 | . 이는 word sequence를 sampling할 때 생기는 큰 문제입니다. 모델은 종종 일관성없이 횡설수설합니다. . The Curious Case of Neural Text Degeneration, Ari Holtzman et al. (2019) | . 위를 해결할 트릭은 분포 $P(w|w_{1:t-1})$을 sharp하게 만드는 것입니다. . 가장 높은 확률을 가지는 단어의 likelihood를 높이고 | 가장 낮은 확률을 가지는 단어의 likelihood를 낮추는 것 | . 위 트릭은 softmax의 temperature라고 불립니다. . temperature를 적용한 예시에 대한 시각화입니다. . . temperature를 적용하기 전에는 $P(w|`the`)$에서 car가 뽑힐 확률이 0.1이었지만 지금은 0.02입니다. 낮아진 만큼 뽑히기는 더 힘들겠죠? . sample_output = model.generate( input_ids, do_sample=True, max_length=128, top_k=0, temperature=0.7, ) print(&quot;Output: n&quot; + 100 * &#39;-&#39;) print(tokenizer.decode(sample_output[0], skip_special_tokens=True)) . Output: - 근육이 커지기 위해서는 칼슘과 마그네슘이 풍부한 음식을 꾸준히 섭취하는 것이 좋다. 또한 규칙적인 운동, 스트레스 유발과 같은 생활습관 관리에도 신경을 써야 한다. 한양대병원 가정의학과 양형철 교수는 “지방간 질환을 개선하고 삶의 질을 높이는 데 도움이 되는 비타민D와 칼슘을 많이 섭취하면 간 건강에 도움이 될 수 있다”며 비타민D, 칼슘, 마그네슘이 풍부한 음식을 꾸준히 섭취하는 것이 간 건강에 도움이 된다고 조언했다. 서울시는 오는 10일 오후 5시30분 마포구 서교동 홍익대 인근 선유도공원에서 &#39;플라워 페스티벌-선유도공원을 찾아라&#39; 행사를 개최한다고 9일 . Maximization의 결과와 유사하면서 반복은 안하고 다른 내용까지 추가되었습니다! (물론 근육과는 아직도 관련이 적습니다... 그래도 일관성은 개선되었군요.) . temperature를 적용하면 분포를 덜 random하게 만들 수 있지만 0으로 설정하면 greedy decoding과 동일해집니다. 그러면 이전과 같은 문제를 다시 겪게 되겠지요. . Top-K Sampling . Fan 연구진은 아주 간단하지만 강력한 sampling scheme인 Top-K를 소개했습니다. . Hierarchical Neural Story Generation, Fan et. al (2018) | . Top-K sampling에서 가장 가능성이 높은 K개의 다음 단어는 filtering되고 probability mass는 K개의 다음 단어에 대해서만 재분배됩니다. GPT2가 이 sampling scheme를 택했고 story generation에서 성공적이었던 원인 중 하나로 평가됩니다. . 전체 단어 분포에서 샘플링하는 것이 아니라 고정된 상위 K개의 단어에서 sampling 수행 | . . Time step 1에서 Top-6개를 제외한 나머지 people, big, house, cat은 생성 대상에서 제거합니다. (Top-K개만 filtering, Vocab에 pick-up) . Step 1에서는 전체의 2/3, step 2에서는 거의 모든 probability mass를 포함합니다. . Time step 2에서 Top-6개를 제외한 나머지 not, the, small, told 이상한 단어들을 성공적으로 제외하고 추출하는 것을 확인할 수 있습니다. . sample_output = model.generate( input_ids, do_sample=True, max_length=128, top_k=50, ) print(&quot;Output: n&quot; + 100 * &#39;-&#39;) print(tokenizer.decode(sample_output[0], skip_special_tokens=True)) . Output: - 근육이 커지기 위해서는 성장호르몬이 많이 분비돼야 하는데, 반대로 성장세포 주사를 맞고 자라기 위해서는 부족한 영양소가 필요하게 된다. 성장호르몬이 부족하면 혈액의 원활한 흐름을 돕는 비타민A가 풍부해지지만, 성장세포가 부족하면 혈액의 흐름이 원활하지 않게 돼 영양공급이 제대로 이뤄지질 못한다는 것은 매우 치명적이다. 성인이라면 보통 10~15% 정도 성장이 잘 되지만, 20, 30대 중년 남성들과 고연령층의 경우, 40, 50대 중년 여성들보다 더 큰 성장이 필요하다. 이뿐 아니라 성호르몬 수치는 더 빨리 감소하는 경향이 있다는 연구결과도 있다. 연구팀들은 호르몬이 부족하면 혈액 공급이 부족하고, 혈액 내 . 제일 괜찮은 결과인 것 같습니다! 가장 인간같이 생성된 것 같군요. Top-K sampling의 한 가지 문제는 next word distribution $P(w|w_{1:t-1})$에서 filtering되는 단어의 수를 dynamic하게 적용하지 않는 다는 점입니다. . 고정된 K를 사용하기에 문제 | . 위 그래프에서 오른쪽의 경우 매우 sharp한 분포에서 sampling되지만 왼쪽의 경우에는 더 flat한 분포에서 sampling되기에 문제가 될 수 있습니다. . Step 1에서 Top-K는 people, big, house, cat 와 같은 가능성있는 후보군들을 제외했습니다. 반대로 Step 2에서는 단어의 sample pool(In top-k)에 부적합한 단어 down, a를 포함합니다. 때문에 sample pool은 고정된 크기 K로 제한하는 것은 모델이 sharp distribution에 대해 횡설수설(gibberish)할 위험이 있고 flat distribution에 대해 창의성(creativity)이 제한될 수 있습니다. . 위 직관이 Ari Holtzman 연구진들이 제안한 Top-p 혹은 nucleus sampling으로 이어집니다. . Top-p (nucleus) Sampling . 가장 높은 K개의 단어를 선택하는 대신 Top-P sampling은 누적 확률이 확률 p를 초과하는 가능한 가장 작은 단어 집합에서 선택합니다. 그런 다음 probability mass는 이 단어 set 사이에 재분배됩니다. 이런 식으로 단어 집합의 크기(a.k.a the number of words in the set)은 다음 단어의 확률 분포에 따라 동적으로 증가하거나 감소할 수 있습니다. . 위를 시각화해봅시다! . . $p=0.92$로 설정하겠습니다. Top-p sampling은 probability mass의 92%를 초과하는 단어의 minimum number를 계산합니다. 이를테면 위에서 cat을 제외한 단어의 prob mass의 합은 0.94로 설정한 p보다 커지게 됩니다. 즉 time step 1에서는 9개의 단어를 고르고 time step 2에서는 drives, is, turns 만으로도 97%입니다. 때문에 3개의 단어로 고정 후 sampling을 수행합니다. Top-K에서 고정적인 K로 sampling한 것과 다르게 Top-p에서는 next word distribution에 따라 dynamic하게 sampling pool을 결정할 수 있습니다. . sample_output = model.generate( input_ids, do_sample=True, max_length=128, top_p=0.92, top_k=0, ) print(&quot;Output: n&quot; + 100 * &#39;-&#39;) print(tokenizer.decode(sample_output[0], skip_special_tokens=True)) . Output: - 근육이 커지기 위해서는 물 속에 오래 있다가 맥주를 삼키는 것이 도움이 된다. 몸이 차가워지면 아드레날린이 분비되어 농도가 높아지므로, 몸에 쌓인 아드레날린 분비를 조절해야 한다. 따라서 8000mg에서 90mg 정도 먹는 것이 바람직하다. 박 교수는 “최근 유행하는 프리바이오틱스는 장내 미생물의 증식 등 고유의 특성을 갖고 있다. 그러나 장에도 많은 종류의 유산균이 증식하기 때문에 다양하긴 하지만 장에 유익한 균이 많이 생성되지 않는 편”이라고 밝혔다. 정답은 ‘공부 비법’이다. 공부에 빠진 아이들의 세포막을 현미경으로 들여다본다. 아기처럼 희고 건강한 베개를 만든 . 좋습니다! 맨 처음 sampling했을 결과보다는 훨씬 더 사람다워 졌습니다. (내용은...) . 이론적으로 Top-p는 Top-k보다 더 우아해보이지만 실제로는 두 방법 모두 잘 동작하고 Top-p는 Top-k와 함께 사용할 수 있습니다. Top-K는 매우 낮은 순위의 단어를 피하면서 일부 동적 선택을 허용할 수 있습니다. . 마지막으로 독립적으로 샘플링된 여러 출력을 얻기 위해 매개변수 num_return_sequences를 1보다 크게 다시 설정할 수 있습니다. . sample_outputs = model.generate( input_ids, do_sample=True, max_length=128, top_p=0.95, top_k=50, num_return_sequences=3, ) print(&quot;Output: n&quot; + 100 * &#39;-&#39;) for i, sample_output in enumerate(sample_outputs): decoded_text = tokenizer.decode(sample_output, skip_special_tokens=True) print(f&quot;{i}: {decoded_text}&quot;, end=&quot; n n&quot;) . Output: - 0: 근육이 커지기 위해서는 비타민 C가 매우 중요한데, 이 비타민C가 뇌를 건강하게 만드는 데 필요한 핵심 영양소가 되기 때문이다. 또한 아연이 많이 함유된 음식을 섭취할 경우 심장병이 위험할 수 있으므로, 음식을 씹는 횟수를 줄이도록 하고 비타민 C가 많이 함유된 식품을 꾸준히 섭취하는 것이 좋다. 또한 비타민 C를 많이 함유한 식품은 스트레스를 해소하고 다이어트에도 도움이 되며, 뇌졸중을 예방하는 효과도 기대할 수 있다. 이런 이유로 최근에는 ‘건강한 우리 몸’에서 탄수화물과 지방, 단백질과 비타민을 조합하는 발효식품이 관심을 받고 있다. 당근과 생강은 혈중 비타민을 보충해 심혈관계에 도움을 1: 근육이 커지기 위해서는 먼저 몸에 무리가 가지 않도록 하는 것이 중요하다. LG전자의 새로운 디자인 콘셉트인 &#39;매직스페이스&#39;는 혁신적인 디자인을 넘어 제품 성능이 업그레이드 된 것을 의미한다. LG전자는 올해 선보인 올레드 TV의 &#39;프리미엄&#39; 콘셉트인 &#39;매직스페이스&#39;를 통해 LG만의 &#39;3세대&#39;(4K) OLED(유기발광다이오드), &#39;스마트 OLED(유기발광다이오드)&#39; 등으로 확대해 프리미엄 라인업의 경쟁력을 강화해 나간다는 방침이다. LG전자는 특히 OLED의 경우 2: 근육이 커지기 위해서는 우선 피부 자체의 균형이 중요하다. 특히 건조한 피부의 경우 수분 공급에 대한 적절한 관리만이 피부 톤을 건강하게 되찾아 주는 최선의 방법이다. 더페이스샵의 ‘더페이스샵 수분 크림’은 수분크림으로 사용 시 수분이 더욱 강하게 흡수돼 피부 본연의 피부 보습에 도움을 줄 수 있다. 특히 피부의 수분함유량에 따라서 다양한 제품이 개발되며 수분크림을 바른 후 피부톤까지 환하게 밝혀주고 있다. 바디 전용 앰플 타입의 고보습 수분크림은 자외선차단 기능이 있어 여름철 야외활동이 많은 환절기에 적합하다. 특히 여름철 민감피부에는 바르는 즉시 피부에 보습막을 형성해 주는 . Conclusion . top-p, top-k sampling은 open-ended language generation에서 기존의 greedy-and beam search보다 더 유창한 text를 생성하는 것으로 보임 | 최근에 greedy 및 beam search의 명백한 경함(주로 반복적인 word sequence 생성)이 decoding methodology보다는 model(특히 모델이 훈련되는 방식)에 의해 발생한다는 증거가 더 많이 있음. Neural Text Degeneration with Unlikelihood Training, Welleck et al., (2019) | . | 또한 top-k 및 top-p sampling도 repetitive word sequence 생성에서 자유롭진 못하는 것으로 보임 Consistency of a Recurrent Language Model With Respect to Incomplete Decoding, Welleck et al., (2020) | . | Welleck의 2019 연구에 의하면 저자는 사람의 평가에 따르면 모델의 훈련 목표를 조정할 때 Beam search가 Top-p sampling보다 더 유창한 text를 생성할 수 있음을 보임 | Open-ended language generation은 빠르게 발전하는 분야이며 여기에 모든 경우에 적용할 수 있는 방법이 없는 경우가 많음. 때문에 특정 사용 사례에 가장 적합한 방법이 무엇인지를 확인해야 한다. | . Appendix . 위에서 언급하지 않은 생성 메소드에 대한 몇 가지 추가 매개변수 소개 . min_length: min_lenght에 도달하기 전에 모델이 EOS token을 생성하지 않도록 강제하는 데 사용할 수 있음 요약에서 매우 자주 사용되지만 사용자가 더 긴 출력을 원할 경우 일반적으로 유용할 수 있음 | . | repeat_penalty: 이미 생성되었거나 context에 속하는 단어에 penalty를 적용하는데 사용. Keskar et al., (2019)에 의해 처음으로 소개되었으며 Welleck et al., (2019)의 training objective로도 사용됨. 반복을 방지하는데 매우 효과적일 수 있지만 다양한 모델 및 사용 사례에 매우 민감한 것으로 보임. 해당 디스커션 참고. CTRL: A Conditional Transformer Language Model for Controllable Generation, Keskar et al., (2019) | Neural Text Degeneration with Unlikelihood Training, Welleck et al., (2019) | . | attention_mask: padded token을 mask하는데 사용 | pad_token_id, bos_token_id, eos_token_id: 모델에 기본적으로 해당 토큰이 없는 경우 사용자는 다른 token id를 수동으로 선택하여 나타낼 수 있음. | . GenerationMixin &#46895;&#50612;&#48372;&#44592; .",
            "url": "https://jinmang2.github.io/%F0%9F%A4%97%20huggingface/nlp/2022/03/01/how-to-generate.html",
            "relUrl": "/%F0%9F%A4%97%20huggingface/nlp/2022/03/01/how-to-generate.html",
            "date": " • Mar 1, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "The Reversible Residual Networks",
            "content": "RevNet . 2017년도에 나온 논문 | 딥러닝 논문 읽기 모임에서 h-transformer-1d 논문을 뜯어보다 발견한 기법 | 찾아보니 lucidrains님이 reformer를 구현하며 사용한 _ReversibleFunction을 이후 transformer 구현체에 사용하는 것을 발견 | residual connection의 단점인 Memory consumption을 개선한 기법 | . Abstract . Residual Conncetion의 bottleneck: Memory Consumption 역전파 시 gradient 계산을 위해서 필요하다고 한다. | . | 위 문제를 개선한 ResNet의 variant인 RevNet을 소개 각 layer의 activation (output)들을 다음 layer의 activation으로 reconstruct 가능 | 때문에 역전파 동안에 모든 layer의 activation을 저장할 필요가 없게 된다. | . | RevNet을 CIFAR-10, CIFAR-100, ImageNet에서 실험 동일한 accuracy | depth와 무관한 activation storage 요구 | . | . Introduction . Residual connection: key architecture innovation 더 깊게 쌓아도 gradient vanishing/exploding없이 information이 쭉 전달될 수 있게 만들어 줌 | . | 최근 거의 모든 신경망은 Backpropagation으로 학습됨 | backpropagation 과정 중 network의 activation을 메모리에 저장함 아래 코드는 Matrix Multiplication을 torch autograd 모듈로 작성한 코N | . class Matmul(torch.autograd.Function): @staticmethod def forward(ctx, x, W): ctx.save_for_backward(x, w) # backward 연산을 위해 값을 저장 return x @ W @staticmethod def backward(ctx, grad_outputs): x, W, = ctx.saved_tensors # 미분 연산에 사용될 값 호출 return grad_outputs @ W.T, x.T @ grad_outputs . | Neural Network는 깊게 쌓을수록 성능이 향상된다고 이미 보고된 바가 있고 ResNet 또한 정보가 backward 과정에서 잘 흐를 수 있도록 residual connection을 붙인 것 | ResNet은 information flow를 개선한 것이지 backward 연산의 bottleneck을 해결한 것이 아님 | GPU 자원은 한정되어 있음 | 이러한 연유로 Large model을 학습시킬 때 multiple GPU 환경에서 Parallelism이 필수지만 이는 비싸고 구현하기 복잡함 | 따라서 본 논문에서 RevNet을 제안함 A variant of ResNets which is reversible in the sense that each layer’s activations can be computed from the next layer’s activations | 위 문장이 핵심이라고 생각함. 각 layer의 activation이 다음 layer의 activation으로 계산이 가능하다는 말(reversible) | 잘 이해가 안되면 3장의 수식 부분을 읽는 것이 빠름 | . | 신기하게 이러한 구조를 사용했을 때 성능 하락이 발생하지 않았다고 보고함 Surprisingly, constraining the architecture to be reversible incurs no noticeable loss in performance | . | . Background . Backpropagation . $ theta= theta- alpha nabla_ theta f_ theta$ | 핵심은 chain rule | torch, tensorflow, theano에선 automatic differentiation 모듈로 구현이 되어있음 | RevNet의 memory savings은 위 모듈의 도움을 받는 것이 아니라(?) backprop computation 부분을 직접 구현함 공식 repo에서는 tensorflow 구현을 수행 (tf.gradients를 사용해서) | 본 논문 리뷰에서는 lucidrains님의 torch 구현체를 사용할 예정 (torch.autograd.Function) | . | Let $v_1, dots,v_k$ be topological ordering of the nodes in the network’s computation graph $ mathcal{G}$, where $v_k$ denotes the cost function $ mathcal{C}$ neural net을 topological graph로 보고 각 node를 $v_i$로 두자는 얘기 | 마지막 노드는 loss를 계산하는 부분일 테니 $v_k$는 cost function이 될 것 | . | 각 노드는 parents 노드의 함수 $f_i$에 의해 정의됨 | Backprop이 원하는 것? total derivative $ frac{d mathcal{C}}{dv_i}$를 계산하는 것! total derivative는 계산 그래프에서 $v_k$의 자손을 통한 간접 효과를 고려하여 $v_i$에 대한 극미한 변화가 $ mathcal{C}$에 미치는 영향을 측정 | [Note that] total derivative $ frac{d mathcal{C}}{dv_i}$와 partial derivative $ frac{ partial f}{ partial x_i}$는 다르다는 것을 명심 partial derivative $ frac{ partial f}{ partial x_i}$는 다른 argument들에 대해 $x_i$가 바뀌는 영향을 고려하지 않는다. | . | . | Let $ bar{v_i}= frac{d mathcal{C}}{dv_i}$ be total derivative | Backprop은 topological order의 역순으로 계산 그래프의 node들을 돈다 | 각 노드 $v_i$에 대해 아래의 식을 활용하여 total derivative를 계산한다. . viˉ=∑j∈Child(i)(∂fj∂vi)⊤vjˉ bar{v_i}= sum_{j in text{Child}(i)} bigg( cfrac{ partial f_j}{ partial v_i} bigg)^ top bar{v_j}vi​ˉ​=j∈Child(i)∑​(∂vi​∂fj​​)⊤vj​ˉ​ where $ text{Child}(i)$는 $ mathcal{G}$의 node $v_i$의 child이고 $ cfrac{ partial f_j}{ partial v_i}$는 Jacobian matrix | chain rule을 써놓은 식이다. | . | . Deep Residual Networks . Deep networks는 수많은 nonlinear function들로 구성된 합성함수(composition function) | 때문에 각기 다른 layer별 종속성은 많이 복잡함 이는 gradient computation을 불안정하게 만듦 | . | 더 깊게 쌓으려면 이를 해결해야할 필요성이 있었음 Highway networks에서 skip connection을 소개하여 이 문제를 피했고 더 정확히는 이 논문은 LSTM에서 영감을 받음 | . | ResNet은 functional form을 사용하여 computations stable을 유지하며 information flow를 개선! y=x+F(x)y=x+ mathcal{F}(x)y=x+F(x) | 여기서 $ mathcal{F}$는 shallow neural network로 self-attention 모듈 등이 될 수 있음 | . | ResNet은 exploding, vanishing gradient 문제에 강건함 | He 연구진은 두 residual block을 사용했다고 함 basic residual function Basic(x)=c3(c3(x))Basic(x)=c_3(c_3(x))Basic(x)=c3​(c3​(x)) | bottleneck residual function Bottleneck(x)=c1(c3(c1(x)))Bottleneck(x)=c_1(c_3(c_1(x)))Bottleneck(x)=c1​(c3​(c1​(x))) | where a(x)=ReLU(BN(x))ack(x)=Convk×k(a(x)) begin{aligned} a(x)=ReLU(BN(x)) ac_k(x)=Conv_{k times k}(a(x)) end{aligned}a(x)=ReLU(BN(x))ack​(x)=Convk×k​(a(x))​ | . | . Reversible Architectures . 본 논문의 동기와는 다르지만 reversible neural net architecture들에 대해 몇몇 paper들이 있다고 함 | RevNet은 그 중 NICE라 불리는 nonlinear independent components estimation에 영감을 받아 탄생했다고 언급됨 NICE: an approach to unsupervised generative modeling | https://deepseow.tistory.com/45 | https://deepakbaby.in/post/nice-keras/ | . | NICE는 data space와 latent space 사이의 non-linear bijective transformation를 학습 비선형 1-1 corresponding mapping을 학습 | 양방향으로 복원되고 + 비선형 | RevNet의 아이디어와 유사함 | . | . y1=x1y2=x2+F(x1) begin{aligned} y_1&amp;=x_1 y_2&amp;=x_2+ mathcal{F}(x_1) end{aligned}y1​y2​​=x1​=x2​+F(x1​)​ . 모델이 invertible하고 Jacobian이 unit determinant를 가지기 때문에 log-likelihood와 gradient 계산이 다루기 쉬움 Invertible? $x_1=y_1$, $x_2=y_2- mathcal{F}(y_1)$ | Jacobian이 unit determinant를 가지는 이유? just add! . | . | .",
            "url": "https://jinmang2.github.io/fundamental/2022/02/12/revnet.html",
            "relUrl": "/fundamental/2022/02/12/revnet.html",
            "date": " • Feb 12, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Cross Entropy",
            "content": "Introduction . 본 포스팅에서는 Cross Entropy에 대해 알아보겠습니다. . Cross Entropy의 개념 | Cross Entropy 수식 | Matplotlib으로 figure 그려보기 | Numpy로 코드 구현체 살펴보기 | PyTorch로 forward, backward pass 수식과 함께 이해하기 | PyTorch 결과값과 동일한 출력이 나오도록 코드 수정 | . Cross Entropy&#46976;? . Cross entropy는 random variable(확률 변수) 혹은 set of events(사건 집합)이 주어졌을 때 서로 다른 두 확률 분포 사이의 차이를 재는 measure입니다. . Entropy . Event $x$가 등장할 확률을 $P(x)$라고 두고 이에 대한 정보량 $h(x)$에 대한 수식은 아래와 같이 정의됩니다. . $$h(x)=- log{P(x)}$$ . $ log$ 함수의 그래프에 음수를 씌우면 아래와 같이 그릴 수 있습니다. . import numpy as np import matplotlib.pyplot as plt x = np.linspace(0.01, 1, 100) y = - np.log(x) plt.axvline(0, color=&quot;k&quot;, alpha=0.7) plt.axhline(0, color=&quot;k&quot;, alpha=0.7) plt.plot(x, y, lw=3) plt.xlabel(&quot;probability&quot;) plt.ylabel(&quot;information&quot;) plt.grid() _ = plt.plot() . 위 그래프로부터 아래의 사실을 확인할 수 있습니다. . $P(x)$가 0.0에 가까울 때 (사건이 등장할 확률이 희박할 때) 해당 사건에 대한 정보량이 높음을 알 수 있습니다. | $P(x)$가 1.0에 가까울 때 (사건이 등장할 확률이 높을 때) 해당 사건에 대한 정보량이 낮음을 알 수 있습니다. | . 때문에 이를 정보 이론에서는 surprise 라고 묘사합니다. 우리가 매일 마주하는 일상에서는 크게 놀랄만한 정보가 없습니다. 그러나 취업을 했달지 연애를 시작한다던지 인생에 드물게 찾아오는 사건이 생기면 우리는 이 기쁨에 취하며 놀라곤 합니다. . 즉, 드물게 발생할 수록 더욱 정보량이 높은 것이지요. . 단일 사건에 대한 정보량말고 set of $x$, $X$를 생각해보겠습니다. $X$는 이산 확률 분포라고 가정할게요. 그러면 다음과 같이 식을 적을 수 있습니다. . $$H(X)=- sum_{x in X}P(x) cdot log{P(x)}$$ . $X$의 모든 사건 $x$에 대한 정보량들을 더한 값을 $X$에 대한 정보량으로 생각할 수 있다라고 식이 적혀있습니다. Entropy는 가능한 모든 사건이 발생할 확률이 전부 같을 때 최댓값을 가집니다. 각각의 정보량은 발생할 확률이 작을수록 값이 커지기 때문이죠. . &#51060;&#49328;&#48320;&#49688;&#51032; Entropy . Discrete variable의 기댓값은 summation으로 쓸 수 있습니다. 위의 수식을 잘 살펴보죠. 기댓값의 수식이죠? . $$ begin{aligned} H(X)&amp;=- sum_{x in X}P(x) cdot log{P(x)} &amp;= sum_{x in X}P(x) cdot(- log{P(x)}) &amp;= mathbb{E} big[- log{P(x)} big] end{aligned} $$위 수식을 잘 기억해주세요. 이산변수는 기댓값을 합으로 계산하기 때문에 아래와 같이 쉽게 계산할 수 있습니다. . 확률 분포 Y가 이산분포이고 다음과 같다고 가정해보겠습니다. . 확률 분포 $Y_1$: $P(Y=0)=0.8, ;P(Y=1)=0.2$ | . $Y_1$에 대한 entropy를 정의된 식과 같이 동일하게 계산할 수 있습니다. . p_y = [0.8, 0.2] sum([p * -np.log2(p) for p in p_y]) . 0.7219280948873623 . &#50672;&#49549;&#48320;&#49688;&#51032; Entropy . 이와는 다르게 Continuous variable의 기댓값은 Integral로 쓸 수 있습니다. . $$ begin{aligned} H(X)&amp;= mathbb{E} big[- log{P(X)} big] &amp;= int_{- infty}^{ infty}{P(X) cdot(- log{P(X)})}dx end{aligned} $$위를 trapezoidal rule을 사용하여 적분값을 계산해보겠습니다. . def normal(x, mu, sigma): var = sigma ** 2 x = x - mu return (1 / np.sqrt(2 * np.pi * var)) * np.exp(-x**2 / (2 * var)) entropy = lambda p: -p * np.log(p) def trapezoidal_rule(dt, p, f): return np.sum((f(p[:-1]) + f(p[1:])) * dt) / 2 xlim, ylim, n_sample, n_bin = 10, 0.5, 50000, 1000 yticks = [0.1, 0.2, 0.3, 0.4, 0.5] mu1, mu2 = 0.0, 0.0 sigma1, sigma2 = 1.0, 2.5 x = np.linspace(-xlim, xlim, n_sample) X1 = np.random.normal(loc=mu1, scale=sigma1, size=(n_sample)) X2 = np.random.normal(loc=mu2, scale=sigma2, size=(n_sample)) fig = plt.figure(figsize=(8, 4)) def plot_normal_entropy(ax, X, mu, sigma): _, bins, _ = ax.hist(X, bins=n_bin, density=True, histtype=&quot;stepfilled&quot;, color=&quot;slateblue&quot;, edgecolor=&quot;k&quot;, lw=0.1) ax.plot(x, normal(x, mu, sigma), color=&quot;k&quot;, lw=2) ax.set_ylim(0, ylim) ax.set_yticks(yticks) dt = np.diff(bins) p = normal(bins, mu, sigma) ent = trapezoidal_rule(dt, p, entropy) ax.set_title(rf&quot;N(${mu}$, ${sigma}^2$) H(p)={ent:.4f}&quot;) plot_normal_entropy(fig.add_subplot(1, 2, 1), X1, mu1, sigma1) plt.ylabel(&quot;probability&quot;) plot_normal_entropy(fig.add_subplot(1, 2, 2), X2, mu2, sigma2) _ = plt.plot() . 위처럼 직접 적분값을 근사하여 계산할 수도 있지만 정규 분포 엔트로피 값을 해석적으로도 계산할 수 있습니다. . 정규 분포의 수식은 아래와 같습니다. . $$P(X)= cfrac{1}{ sqrt{2 pi sigma^2}} exp{ bigg( cfrac{-(X- mu)^2}{2 sigma^2} bigg)}$$ . 이제 엔트로피 수식을 전개해봅시다. . $$ begin{aligned} H(X)&amp;= mathbb{E} big[- log{P(X)} big] &amp;= int_{- infty}^{ infty}{P(X) cdot(- log{P(X)})}dX end{aligned} $$여기서 $- log P(X)$는 $ cfrac{1}{2} log{2 pi sigma^2}+ cfrac{1}{2 sigma^2}(X- mu)^2$이고 이를 대입하면 . $$ H(X)= cfrac{1}{2} log{2 pi sigma^2} int_{- infty}^{ infty}{P(X)}dX+ cfrac{1} {2 sigma^2} int_{- infty}^{ infty}(X- mu)^2P(X)dX $$여기서 확률 및 분산의 정의에 따라 다음을 알 수 있고 . $$ int_{- infty}^{ infty}{P(X)}dX=1$$ $$ int_{- infty}^{ infty}(X- mu)^2P(X)dX= sigma^2$$ . 이를 사용하여 식을 다시 작성하면 . $$H(X)= cfrac{1}{2} big( log{2 pi sigma^2}+1 big)$$ . 와 같이 쓸 수 있습니다. . python code로 구현하여 위의 결과와 비교해봅시다. . def normal_entropy(sigma): # return 0.5 * np.log(np.e * 2 * np.pi * sigma**2) return 0.5 * (1 + np.log(2 * np.pi * sigma**2)) normal_entropy(sigma1) . 1.4189385332046727 . Cross Entropy . Machine Learning: A Probabilistic Perspective에서는 cross entropy를 다음과 같이 설명합니다. . The cross entropy is the average number of bits needed to encode data coming from a source with distribution p when we use model q ... . $P$는 모델링하고자 하는 분포, $Q$는 모델링을 할 분포라고 생각하면 이해가 빠릅니다. $P$ 대신 $Q$를 사용하여 사건을 나타내는 총 비트의 평균 수 입니다. . $$H(P,Q)=- sum_{x in X}P(x) cdot log Q(x)$$ . 총 비트 수가 아니라 추가로 필요한 비트의 평균값은? relative entropy, Kullback-Leibler Divergence 라고 합니다. . $$KL(P||Q)=- sum_{x in X}P(x) cdot log{ cfrac{Q(x)}{P(x)}}$$ . 위 수식은 Entropy와 엮어서 다음과 같이 쓸 수 있습니다. . $$ begin{aligned} H(P)&amp;= sum_{x in X} P(x) cdot log P(x) &amp;=H(P,Q)-KL(P||Q) end{aligned} $$ Cross-entropy and Maximum Likelihood Estimation . 분류 문제를 풀기 위해 Neural Network를 학습시킬 때, 우리는 흔히 Cross Entropy로 학습시킵니다. 왜일까요? . 위에서 Entropy, Cross Entropy, KL-Divergence에 대한 수식을 정의했습니다. . 앞서 확률 변수의 Entropy 정의에서 Entropy가 확률 변수의 Expectation과 관련이 있음을 확인했었습니다. 각각을 기댓값 표현으로 써보면, . $$ begin{aligned} H(X)&amp;=- sum_x p(x) log p(x) &amp;= sum_x -p(x) log p(x) &amp;= sum_x p(x) log cfrac{1}{p(x)} &amp;= mathbb{E}_{X sim p(x)} bigg[ log cfrac{1}{p(x)} bigg] end{aligned} $$$$ begin{aligned} KL(p||q)&amp;= sum_x p(x) log cfrac{p(x)}{q(x)} &amp;= mathbb{E}_{X sim p(x)} bigg[ log cfrac{p(x)}{q(x)} bigg] &amp;= mathbb{E}_{X sim p(x)} bigg[ log cfrac{1}{q(x)}- cfrac{1}{p(x)} bigg] &amp;= mathbb{E}_{X sim p(x)} bigg[ log cfrac{1}{q(x)} bigg]- mathbb{E}_{X sim p(x)} bigg[ log cfrac{1}{p(x)} bigg] &amp;= mathbb{E}_{X sim p(x)} bigg[ log cfrac{1}{q(x)} bigg] - H(p) end{aligned} $$Cross entropy는 아래와 같이 적을 수 있죠. . $$H(p,q)= mathbb{E}_{X sim p(x)} bigg[ log cfrac{1}{q(x)} bigg]$$ . 그러면 Maximum Likelihood Estimation에서의 objective function을 살펴보겠습니다. . 우리는 분포 $p$를 모델링하고 싶습니다. 이에 대한 데이터 $X$를 모수 $ theta$를 가지는 parametric model $q$로 모델링하면 아래와 같이 수식을 쓸 수 있습니다. . $$ theta_{ML}= underset{ theta}{ mathrm{argmax}} ;q(X; theta)$$ . i.i.d 가정에 의해 아래와 같이 수식을 작성하면 (로그 스케일로) . $$ begin{aligned} theta_{ML}&amp;= underset{ theta}{ mathrm{argmax}} ; prod_{i=1}^{m}q(x_i; theta) &amp;= underset{ theta}{ mathrm{argmax}} ; sum_{i=1}^{m} log q(x_i; theta) &amp;= underset{ theta}{ mathrm{argmax}} ; sum_{i=1}^{m} frac{1}{m} log q(x_i; theta) &amp;= underset{ theta}{ mathrm{argmax}} ; mathbb{E}_{X sim p(x)} big[ log q(x) big] &amp;= underset{ theta}{ mathrm{argmin}} ;- mathbb{E}_{X sim p(x)} big[ log q(x) big] &amp;= underset{ theta}{ mathrm{argmin}} ; mathbb{E}_{X sim p(x)} big[ log frac{1}{q(x)} big] end{aligned} $$즉, Likelihood를 maximize하는 문제는 Cross Entropy를 Minimize하는 문제로 치환할 수 있습니다. . Code Implementation . Cross Entropy를 구현해봅시다. . Library &#54840;&#52636; . import math import numbers from typing import Optional, Tuple, Sequence, Union, Any import numpy as np import torch import torch.nn as nn _TensorOrTensors = Union[torch.Tensor, Sequence[torch.Tensor]] . Numpy&#47196; &#44396;&#54788;&#54616;&#44592;: forward . Cross Entropy는 LogSoftmax와 NegativeLogLikelihood로 계산할 수 있습니다. 위에서 본 것처럼 우도를 최대화하는 문제와 Cross entropy를 최소화하는 문제는 동일하기 때문에 이를 Negative Log likelihood를 최소화하는 문제로 생각해도 무방하겠죠? 이를 활용하여 Cross entropy를 구해봅시다. . 한 가지, 구현 테크닉을 소개드리고자 합니다. softmax 함수는 다음과 같은 특징을 가지고 있습니다. . $$ mathrm{softmax}(x)= mathrm{softmax}(x+c)$$ . 이를 활용하여 overflow 문제를 해결할 수 있습니다. . $$ mathrm{softmax}(x_i)= cfrac{exp(x_i)}{ sum_j exp(x_j)}$$ . def log_softmax_numpy(arr): c = np.amax(arr, axis=-1, keepdims=True) s = arr - c nominator = np.exp(s) denominator = nominator.sum(axis=-1, keepdims=True) probs = nominator / denominator return np.log(probs) . 우도는 fancy indexing으로 간단하게 계산할 수 있습니다. 구한 likelihood에 음수를 씌워주면 Negative Likelihood가 되겠지요. . 구한 Negative Log Likelihood는 평균값으로 reduce하겠습니다. . def negative_log_likelihood_numpy(y_pred, y): log_likelihood = y_pred[np.arange(y_pred.shape[0]), y] nll = -log_likelihood return nll.mean() . Cross entropy는 이제 간단합니다. 예측 값 Q에 log softmax를 취해주고 음의 로그 가능도를 계산해주면 됩니다. . def cross_entropy_numpy(y_pred, y): log_probs = log_softmax_numpy(y_pred) ce_loss = negative_log_likelihood_numpy(log_probs, y) return ce_loss . PyTorch&#47196; &#44396;&#54788;&#54616;&#44592;: forward . 이를 pytorch로도 구현해봅시다. 구현은 메서드명까지 동일합니다. 차이라면 numpy에서는 차원축을 axis라는 parameter로 받는 반면, torch는 dim이라는 parameter로 받습니다. . def log_softmax_torch(tensor): c = torch.amax(tensor, dim=-1, keepdims=True) s = tensor - c nominator = torch.exp(s) denominator = nominator.sum(dim=-1, keepdims=True) probs = nominator / denominator return torch.log(probs) def negative_log_likelihood_torch(y_pred, y): log_likelihood = y_pred[torch.arange(y_pred.shape[0]), y] nll = -log_likelihood return nll.mean() def cross_entropy_torch(y_pred, y): log_probs = log_softmax_torch(y_pred) ce_loss = negative_log_likelihood_torch(log_probs, y) return ce_loss . forward &#44208;&#44284;&#44050; &#48708;&#44368; . import random from functools import partial batch_size = 8 vocab_size = 3000 rtol = 1e-4 atol = 1e-6 isclose = partial(torch.isclose, rtol=rtol, atol=atol) . y_pred = [ [random.normalvariate(mu=0., sigma=1.) for _ in range(vocab_size)] for _ in range(batch_size) ] y_pred_torch = torch.FloatTensor(y_pred) y_pred_torch.requires_grad = True y_pred_numpy = y_pred_torch.detach().numpy() y = [random.randint(0, vocab_size) for _ in range(batch_size)] y_torch = torch.LongTensor(y) y_numpy = y_torch.numpy() . ce_result = nn.CrossEntropyLoss()(y_pred_torch, y_torch) ce_numpy = cross_entropy_numpy(y_pred_numpy, y_numpy) ce_torch = cross_entropy_torch(y_pred_torch, y_torch) try: isclose(ce_result, ce_torch).item() isclose(ce_result, torch.tensor(ce_numpy)).item() success = True except: success = False print(&quot;Do both output the same tensors?&quot;, &quot;🔥&quot; if success else &quot;💩&quot;) if not success: raise Exeption(&quot;Something went wrong&quot;) . Do both output the same tensors? 🔥 . PyTorch&#47196; &#44396;&#54788;&#54616;&#44592;: backward . Log Softmax . $$o(1-o)$$ . 1은 크로네클 델타 | log softmax가 계산 상 이점이 큼 | loss를 더 크게 만들어 주기도 | softmax의 backward의 grad_outputs에 log 함수의 역함수인 1/x를 넣어주면 log_softmax의 backward form이 나온다. | . def _softmax(tensor: torch.Tensor, dim: int = -1) -&gt; torch.Tensor: c = torch.amax(tensor, dim=dim, keepdims=True) s = tensor - c nominator = torch.exp(s) denominator = nominator.sum(dim=dim, keepdims=True) probs = nominator / denominator return probs class Softmax(torch.autograd.Function): @staticmethod def forward(ctx: Any, tensor: Any, dim: int = -1) -&gt; Any: probs = _softmax(tensor) ctx.save_for_backward(probs, torch.tensor(dim)) return probs @staticmethod def backward(ctx: Any, grad_outputs: Any) -&gt; Any: probs, dim, = ctx.saved_tensors grad_outputs -= (grad_outputs * probs).sum(dim.item(), keepdims=True) return probs * grad_outputs, None softmax = Softmax.apply class LogSoftmax(torch.autograd.Function): @staticmethod def forward(ctx: Any, tensor: Any, dim: int = -1) -&gt; Any: probs = _softmax(tensor) ctx.save_for_backward(probs, torch.tensor(dim)) return torch.log(probs) @staticmethod def backward(ctx: Any, grad_outputs: Any) -&gt; Any: probs, dim, = ctx.saved_tensors grad_outputs -= probs * grad_outputs.sum(dim=dim.item(), keepdims=True) return grad_outputs, None log_softmax = LogSoftmax.apply . x = torch.randn(5, 3, requires_grad=True) # Softmax check # -- forward pass y_orig = nn.functional.softmax(x, dim=-1) y_impl = y = softmax(x, -1) assert isclose(y_orig, y_impl).all(), &quot;💩&quot; # -- backward pass dy_orig = torch.autograd.grad(y_orig, x, torch.ones_like(x), retain_graph=True)[0] dy_impl = torch.autograd.grad(y_impl, x, torch.ones_like(x), retain_graph=True)[0] assert isclose(dy_orig, dy_impl).all(), &quot;💩&quot; # LogSoftmax check # -- forward pass y_orig = nn.functional.log_softmax(x, dim=-1) y_impl = y = log_softmax(x, -1) assert isclose(y_orig, y_impl).all(), &quot;💩&quot; # -- backward pass dy_orig = torch.autograd.grad(y_orig, x, torch.ones_like(x), retain_graph=True)[0] dy_impl = torch.autograd.grad(y_impl, x, torch.ones_like(x), retain_graph=True)[0] assert isclose(dy_orig, dy_impl).all(), &quot;💩&quot; # Log + Softmax check # -- forward pass y1 = torch.log(softmax(x, -1)) y2 = log_softmax(x, -1) assert isclose(y1, y2).all(), &quot;💩&quot; # -- backward pass dy1 = torch.autograd.grad(y1, x, torch.ones_like(x), retain_graph=True)[0] dy2 = torch.autograd.grad(y2, x, torch.ones_like(x), retain_graph=True)[0] assert isclose(dy1, dy2).all(), &quot;💩&quot; print(&quot;🔥&quot;) . 🔥 . Negative Log Likelihood . class NegativeLogLikelihoodLoss(torch.autograd.Function): @staticmethod def forward(ctx: Any, y_pred: Any, y: Any) -&gt; Any: bsz, n_classes = torch.tensor(y_pred.size()) ctx.save_for_backward(bsz, n_classes, y) log_likelihood = y_pred[torch.arange(bsz), y] nll = -log_likelihood return nll.mean() @staticmethod def backward(ctx: Any, grad_outputs: Any) -&gt; Any: bsz, n_classes, y, = ctx.saved_tensors grad_outputs = grad_outputs.expand(bsz) / bsz negative_grad = -grad_outputs ll_grad = torch.zeros(bsz, n_classes, device=grad_outputs.device) ll_grad[torch.arange(bsz), y] = 1. grad_outputs = torch.diag(negative_grad) @ ll_grad return grad_outputs, None nll_loss = NegativeLogLikelihoodLoss.apply . Cross Entropy . class CrossEntropyLoss(nn.Module): def forward( self, y_pred: _TensorOrTensors, y: _TensorOrTensors ) -&gt; _TensorOrTensors: log_probs = log_softmax(y_pred) ce_loss = nll_loss(log_probs, y) probs = torch.exp(log_probs) / log_probs.size(0) self.save_for_backward(probs, y, y_pred.size(-1)) return ce_loss def save_for_backward(self, *args): self.saved_tensors = args @torch.no_grad() def backward(self, grad_outputs: _TensorOrTensors) -&gt; _TensorOrTensors: probs, y, num_classes, = self.saved_tensors ce_grad = probs - torch.nn.functional.one_hot(y, num_classes=num_classes) return grad_outputs * ce_grad . put everything together . 위의 세 모듈을 한데 모아 구현 | ignore_index, reduction 추가 구현 | 설명은 시간이 되면 추가로 포스팅 업데이트 | . class LogSoftmax(torch.autograd.Function): @staticmethod def forward(ctx: Any, tensor: Any, dim: int = -1) -&gt; Any: # softmax(x) = softmax(x+c) c = torch.amax(tensor, dim=dim, keepdims=True) s = tensor - c # Calculate softmax nominator = torch.exp(s) denominator = nominator.sum(dim=dim, keepdims=True) probs = nominator / denominator # Calculate log log_probs = torch.log(probs) ctx.save_for_backward(probs, torch.tensor(dim)) return log_probs @staticmethod def backward(ctx: Any, grad_outputs: Any) -&gt; Any: # https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/SoftMax.cpp#L219 probs, dim, = ctx.saved_tensors grad_outputs -= probs * grad_outputs.sum(dim=dim.item(), keepdims=True) return grad_outputs, None class NegativeLogLikelihoodLoss(torch.autograd.Function): @staticmethod def forward(ctx: Any, y_pred: Any, y: Any, dim: int = -1, reduce: str = &quot;mean&quot;, ignore_index: int = -1) -&gt; Any: bsz, n_classes = torch.tensor(y_pred.size()) mask = y.ne(ignore_index) ctx.save_for_backward( bsz, n_classes, y, torch.tensor(dim), mask, torch.tensor({&quot;mean&quot;: 0, &quot;sum&quot;: 1, &quot;none&quot;: 2}.get(reduce, -1)), torch.tensor(ignore_index) ) dim_x = torch.arange(bsz) if dim != 0 else y dim_y = y if dim != 0 else torch.arange(bsz) log_likelihood = y_pred[dim_x, dim_y] # Calculate Log Likelihood nll = -log_likelihood # Calculate Negative Log Likelihood # Calculate Loss if reduce == &quot;mean&quot;: return torch.mean(nll[mask]) elif reduce == &quot;sum&quot;: return torch.sum(nll[mask]) nll[~mask] = 0. return nll @staticmethod def backward(ctx: Any, grad_outputs: Any) -&gt; Any: bsz, n_classes, y, dim, mask, reduce, ignore_index, = ctx.saved_tensors if reduce.item() != 2: # reduce case grad_outputs = grad_outputs.expand(bsz) if reduce.item() == 0: # mean case grad_outputs = grad_outputs / mask.sum() negative_mean_grad = -grad_outputs # backward negative # backward log likelihood (indexing) if dim.item() != 0: ll_grad = torch.zeros(bsz, n_classes, device=grad_outputs.device) ll_grad[torch.arange(bsz), y] = 1 ll_grad[torch.arange(bsz), ignore_index.item()] = 0 else: ll_grad = torch.zeros(n_classes, bsz, device=grad_outputs.device) ll_grad[y, torch.arange(bsz)] = 1 ll_grad[ignore_index.item(), torch.arange(bsz)] = 0 grad_outputs = torch.diag(negative_mean_grad) @ ll_grad return grad_outputs, None, None, None, None class CrossEntropyLoss(nn.Module): log_softmax = LogSoftmax.apply negative_log_likelihood = NegativeLogLikelihoodLoss.apply def __init__(self, reduce: str = &quot;mean&quot;, ignore_index: int = -1): super().__init__() self.reduce = reduce self.ignore_index = ignore_index def forward( self, y_pred: _TensorOrTensors, y: _TensorOrTensors, dim: int = -1, ) -&gt; _TensorOrTensors: log_probs = self.log_softmax(y_pred, dim) ce_loss = self.negative_log_likelihood( log_probs, y, dim, self.reduce, self.ignore_index) probs = torch.exp(log_probs) self.save_for_backward(probs, y, y_pred.size(0), y_pred.size(-1)) return ce_loss def save_for_backward(self, *args): self.saved_tensors = args @torch.no_grad() def backward(self, grad_outputs: _TensorOrTensors) -&gt; _TensorOrTensors: probs, y, bsz, num_classes, = self.saved_tensors y = torch.nn.functional.one_hot(y, num_classes=num_classes) ce_grad = probs - y if self.reduce == &quot;mean&quot;: ce_grad = ce_grad / bsz return grad_outputs * ce_grad . Reference . https://machinelearningmastery.com/cross-entropy-for-machine-learning/ | https://stackoverflow.com/questions/61567597/how-is-log-softmax-implemented-to-compute-its-value-and-gradient-with-better | https://math.stackexchange.com/questions/1804805/how-is-the-entropy-of-the-normal-distribution-derived | https://datascienceschool.net/02%20mathematics/10.01%20%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC.html | https://medium.com/konvergen/cross-entropy-and-maximum-likelihood-estimation-58942b52517a | https://discuss.pytorch.org/t/logsoftmax-vs-softmax/21386/4 | https://stackoverflow.com/questions/61567597/how-is-log-softmax-implemented-to-compute-its-value-and-gradient-with-better | https://github.com/pytorch/pytorch/issues/31829 | https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/SoftMax.cpp#L219 | https://github.com/jinmang2/boostcamp_ai_tech_2/blob/main/u-stage/nlp/ch03_rnn/implement_rnn.py | .",
            "url": "https://jinmang2.github.io/implementation/ai-math/2022/02/07/cross-entropy.html",
            "relUrl": "/implementation/ai-math/2022/02/07/cross-entropy.html",
            "date": " • Feb 7, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi! I’m MyunghoonJin . This website 1 (powered by fastpages) is the storage of my trial and error reports from experience or taking lectures. So it maybe contains inaccurate contents. If you find something, or have a question about contents, just feel free to contact me through mail or comment it in each page (comments are linked to my github with utteranc.es) . Nothing &#8617; . |",
          "url": "https://jinmang2.github.io/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jinmang2.github.io/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}